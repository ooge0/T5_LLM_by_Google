from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
# AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.
def t5_promt_test():
    tokenizer = AutoTokenizer.from_pretrained('T5-base')
    model = AutoModelForSeq2SeqLM.from_pretrained('T5-base', return_dict=True)
    sequence = (
        "Data science is an interdisciplinary field[10] focused on extracting knowledge from typically large data sets and applying the knowledge and insights from that data to solve problems in a wide range of application domains.[11] The field encompasses preparing data for analysis, formulating data science problems, analyzing data, developing data-driven solutions, and presenting findings to inform high-level decisions in a broad range of application domains. As such, it incorporates skills from computer science, statistics, information science, mathematics, data visualization, information visualization, data sonification, data integration, graphic design, complex systems, communication and business.[12][13] Statistician Nathan Yau, drawing on Ben Fry, also links data science to humanâ€“computer interaction: users should be able to intuitively control and explore data.[14][15] In 2015, the American Statistical Association identified database management, statistics and machine learning, and distributed and parallel systems as the three emerging foundational professional communities.[16]")
    inputs = tokenizer.encode("sumarize: " + sequence, return_tensors='pt', max_length=512, truncation=True)
    output = model.generate(inputs, min_length=80, max_length=100)
    summary = tokenizer.decode(output[0])
    print(summary)


if __name__ == '__main__':
    t5_promt_test()

